name: Deploy & Run Batch Job

on:
  workflow_run:
    workflows: ["Build and Push Batch Image"]
    types: [completed]
  workflow_dispatch:
    inputs:
      job_name:
        description: "JS entry file to run (e.g. /app/dist/scripts/spotify-backfill.js)"
        required: false
        default: "/app/dist/scripts/spotify-backfill.js"
      job_resource_name:
        description: "K8s Job resource name (metadata.name). If empty, auto-derive from job_name"
        required: false
        default: ""
      dry_run:
        description: "Set DRY_RUN=true or false"
        required: false
        default: "true"
      limit:
        description: "LIMIT for batch size"
        required: false
        default: "200"
      image_tag:
        description: "Image tag to deploy (e.g. sha-<commit>)"
        required: false
        default: ""
      namespace:
        description: "Kubernetes namespace"
        required: false
        default: "default"
      image_pull_secret:
        description: "ImagePullSecret name"
        required: false
        default: "ghcr-secret"
      db_secret_name:
        description: "DB secret name"
        required: false
        default: "db-url-secret"
      db_secret_key:
        description: "DB secret key"
        required: false
        default: "URL"
      spotify_secret_name:
        description: "Spotify secret name"
        required: false
        default: "spotify-secret"

jobs:
  deploy:
    if: ${{ github.event_name == 'workflow_dispatch' || (github.event_name == 'workflow_run' && github.event.workflow_run.conclusion == 'success') }}
    runs-on: ubuntu-latest
    permissions:
      contents: read

    env:
      IMAGE_REPO: ghcr.io/formalbridge/project_alpha/batch
      NAMESPACE: ${{ inputs.namespace || 'default' }}
      JOB_NAME_FILE: ${{ inputs.job_name || '/app/dist/scripts/spotify-backfill.js' }}
      DRY_RUN: ${{ inputs.dry_run || 'true' }}
      LIMIT: ${{ inputs.limit || '200' }}
      IMAGE_PULL_SECRET: ${{ inputs.image_pull_secret || 'ghcr-secret' }}
      DB_SECRET_NAME: ${{ inputs.db_secret_name || 'db-url-secret' }}
      DB_SECRET_KEY: ${{ inputs.db_secret_key || 'URL' }}
      SPOTIFY_SECRET_NAME: ${{ inputs.spotify_secret_name || 'spotify-secret' }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup kubectl
        uses: azure/setup-kubectl@v3
        with:
          version: 'v1.28.0'

      - name: Configure kubeconfig
        env:
          KUBECONFIG_DATA: ${{ secrets.KUBECONFIG }}
        run: |
          set -euo pipefail
          if [ -z "${KUBECONFIG_DATA:-}" ]; then
            echo "ERROR: secrets.KUBECONFIG is missing or empty"; exit 1
          fi
          mkdir -p ~/.kube
          # 원본 YAML인지 확인 후, 아니면 base64 디코드
          if echo "$KUBECONFIG_DATA" | head -n1 | grep -q '^apiVersion:'; then
            printf '%s' "$KUBECONFIG_DATA" > ~/.kube/config
          else
            echo "$KUBECONFIG_DATA" | base64 -d > ~/.kube/config
          fi
          chmod 600 ~/.kube/config

      - name: Derive IMAGE_TAG
        run: |
          if [ "${{ github.event_name }}" = "workflow_run" ]; then
            echo "IMAGE_TAG=sha-${{ github.event.workflow_run.head_sha }}" >> "$GITHUB_ENV"
          elif [ -n "${{ inputs.image_tag }}" ]; then
            echo "IMAGE_TAG=${{ inputs.image_tag }}" >> "$GITHUB_ENV"
          else
            echo "IMAGE_TAG=sha-${{ github.sha }}" >> "$GITHUB_ENV"
          fi

      - name: Render Job manifest with inputs
        run: |
          mkdir -p .out
          export IMAGE_URI="${{ env.IMAGE_REPO }}:${IMAGE_TAG}"

          # Bring through env from job-level
          export NAMESPACE="${{ env.NAMESPACE }}"
          export JOB_NAME_FILE="${{ env.JOB_NAME_FILE }}"
          export DRY_RUN="${{ env.DRY_RUN }}"
          export LIMIT="${{ env.LIMIT }}"
          export IMAGE_PULL_SECRET="${{ env.IMAGE_PULL_SECRET }}"
          export DB_SECRET_NAME="${{ env.DB_SECRET_NAME }}"
          export DB_SECRET_KEY="${{ env.DB_SECRET_KEY }}"
          export SPOTIFY_SECRET_NAME="${{ env.SPOTIFY_SECRET_NAME }}"

          # Derive JOB_RESOURCE_NAME if not explicitly provided via input
          JOB_RESOURCE_NAME_INPUT='${{ inputs.job_resource_name }}'
          if [ -n "$JOB_RESOURCE_NAME_INPUT" ]; then
            JOB_RESOURCE_NAME="$JOB_RESOURCE_NAME_INPUT"
          else
            base="$(basename "$JOB_NAME_FILE")"
            stem="${base%.*}"
            # normalize: lowercase and replace non-alnum with '-'
            JOB_RESOURCE_NAME="$(echo "$stem" | tr '[:upper:]' '[:lower:]' | sed 's/[^a-z0-9-]/-/g')"
          fi
          export JOB_RESOURCE_NAME
          echo "JOB_RESOURCE_NAME=$JOB_RESOURCE_NAME" >> "$GITHUB_ENV"

          # Render template
          envsubst < k8s/jobs/batch-job-template.yml > .out/job.yaml
          echo "--- Rendered manifest ---"
          cat .out/job.yaml

      - name: Apply Job
        run: |
          kubectl -n "$NAMESPACE" delete job "$JOB_RESOURCE_NAME" --ignore-not-found=true
          kubectl -n "$NAMESPACE" apply -f .out/job.yaml
          kubectl -n "$NAMESPACE" get jobs,pods -o wide

      - name: Wait for Job completion (robust)
        run: |
          set -euo pipefail
          TIMEOUT_SECONDS=1800   # 30 minutes
          INTERVAL=10
          START_TIME=$(date +%s)
          END_TIME=$((START_TIME + TIMEOUT_SECONDS))

          echo "Waiting up to ${TIMEOUT_SECONDS}s for job/${JOB_RESOURCE_NAME} in namespace ${NAMESPACE}"

          while [ "$(date +%s)" -lt "$END_TIME" ]; do
            # read job status fields (empty -> treat as 0)
            succeeded=$(kubectl -n "$NAMESPACE" get job "$JOB_RESOURCE_NAME" -o jsonpath='{.status.succeeded}' 2>/dev/null || echo 0)
            failed=$(kubectl -n "$NAMESPACE" get job "$JOB_RESOURCE_NAME" -o jsonpath='{.status.failed}' 2>/dev/null || echo 0)
            active=$(kubectl -n "$NAMESPACE" get job "$JOB_RESOURCE_NAME" -o jsonpath='{.status.active}' 2>/dev/null || echo 0)

            echo "$(date -u +"%Y-%m-%dT%H:%M:%SZ") status: succeeded=${succeeded:-0} failed=${failed:-0} active=${active:-0}"

            if [ -n "$succeeded" ] && [ "$succeeded" != "0" ]; then
              echo "Job succeeded (succeeded=${succeeded})"
              exit 0
            fi

            if [ -n "$failed" ] && [ "$failed" != "0" ]; then
              echo "Job failed (failed=${failed}) - dumping describe and logs"
              kubectl -n "$NAMESPACE" describe job "$JOB_RESOURCE_NAME" || true
              echo "--- Pod list ---"
              kubectl -n "$NAMESPACE" get pods -l job-name="$JOB_RESOURCE_NAME" -o wide || true
              echo "--- Pod logs (last 200 lines) ---"
              kubectl -n "$NAMESPACE" get pods -l job-name="$JOB_RESOURCE_NAME" -o name | xargs -r -n1 kubectl -n "$NAMESPACE" logs --all-containers=true --tail=200 || true
              exit 1
            fi

            sleep "$INTERVAL"
          done

          echo "Timed out waiting for job/${JOB_RESOURCE_NAME} after ${TIMEOUT_SECONDS}s - dumping describe and logs"
          kubectl -n "$NAMESPACE" describe job "$JOB_RESOURCE_NAME" || true
          kubectl -n "$NAMESPACE" get pods -l job-name="$JOB_RESOURCE_NAME" -o wide || true
          kubectl -n "$NAMESPACE" get pods -l job-name="$JOB_RESOURCE_NAME" -o name | xargs -r -n1 kubectl -n "$NAMESPACE" logs --all-containers=true --tail=400 || true
          exit 1

      - name: Stream Job logs (final tail)
        if: always()
        run: |
          set -euo pipefail
          echo "Streaming recent logs for pods of job/${JOB_RESOURCE_NAME}"
          kubectl -n "$NAMESPACE" get pods -l job-name="$JOB_RESOURCE_NAME" -o name | while read -r pod; do
            echo "=== Logs for $pod ==="
            kubectl -n "$NAMESPACE" logs --all-containers=true --tail=500 "$pod" || true
            echo "=== Describe $pod ==="
            kubectl -n "$NAMESPACE" describe "$pod" || true
          done
